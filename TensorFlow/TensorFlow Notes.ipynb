{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#042a68'>Tensorflow Notes</font>\n",
    "\n",
    "Contents:\n",
    "\n",
    "* Add logs to Summary Writer outside from graph\n",
    "* Handle Memory Consumption by Graph\n",
    "* Dynamic vs. Static RNNs\n",
    "* Handle last state from RNN inside graph\n",
    "* Run model without GPU\n",
    "* Change inline setting during training\n",
    "* Get last output from rnn\n",
    "* Batch Normalization\n",
    "* Applying weights regularization\n",
    "* Load part of graph from previous run\n",
    "* Count trainable params\n",
    "* Handle TensorArrays correct way inside tf.while_loop\n",
    "* Explore checkpoints file\n",
    "* Restore part of the tensor from saving\n",
    "\n",
    "*******\n",
    "\n",
    "# <font color='#042a68'>Add logs to Summary Writer outside from graph</font>\n",
    "\n",
    "Usually we use summary writer as follows:\n",
    "\n",
    "![1](tf1.png)\n",
    "\n",
    "\n",
    "\n",
    "As we can see you can get only variables from the graph. But what if we want some post processing(for example mean loss per epochf, not per batch) of just add some self generated data? In this case we may generate summary by hands.\n",
    "\n",
    "![2](tf2.png)\n",
    "\n",
    "************\n",
    "\n",
    "# <font color='#042a68'>Handle Memory Consumption by Graph</font>\n",
    "\n",
    "During training graphs on GPUs you may note that graph take all available free memory. But what in case you have very simple model and just want to run 2 or 3 of the on GPU? For such case you may use config inside session, that will provide to the model only required amount of memory. More about this you may read in tensorflow official docs.\n",
    "\n",
    "![3](tf3.png)\n",
    "\n",
    "********\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Dynamic vs. Static RNNs</font>\n",
    "\n",
    "\n",
    "Just forget about static RNNs, use Dynamic for your purposes. They are faster to build and also not required manual resizing/spliting of the input data\n",
    "\n",
    "![](tf4.png)\n",
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Handle last state from RNN inside graph</font>\n",
    "\n",
    "When using rnn usual we get last state of RNNs and send back the through feed dict:\n",
    "![](tf5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in this case we move last state from GPU memory and backwards. This is unreasonable. We can handle last state inside GPU directly as:\n",
    "![](tf6.png)\n",
    "**********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91e'>Run model without GPU</font>\n",
    "\n",
    "In case you have GPUs on your machine but want to train without them, you should just pass additional env variable CUDA_VISIBLE_DEVICES=” during script call.\n",
    "![](tf7.png)\n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Change inline setting during training</font>\n",
    "![](tf8.png)\n",
    "***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Get last output from rnn</font>\n",
    "![](tf9.png)\n",
    "****************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Batch Normalization</font>\n",
    "Notes based on this paper. I think to understood BN enough just quickly pass through 3rd paragraph. At glance batch normalizaion helps training as the layer does not have to learn offsets in the input data, and can focus on how to best combine features.\n",
    "\n",
    "It seems that when BN is used, such nuances should be considered:\n",
    "\n",
    "If we have usual layer as z=g(Wu+b)\n",
    ", where g(.) is the nonlinearity such as sigmoid or ReLU batch normalization should be applied as z=g(BN(Wu)). Note that BN applied before nonlinearity. Also due to internal shift β existed in BN bias b\n",
    "\n",
    "can be omitted.\n",
    "\n",
    "If we apply batch norm layer from tensorflow we should clear declare param is_training=True/False during training/inference. Because for training and inference different approaches used by BN. To understood what exactly each param handled by layer mean - take a look on algorithms 1 and 2 descriptions in the original paper on pages 3 and 4 accordingly. Really is seems that it’s enough to use tf contrib layer with all default params only with redefined scale param. γ\n",
    "(scale) and β (shift) params will be trainable by default.\n",
    "![](tf10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe sometimes easier use in place update of alpha and beta. In docs was mentioned that this approach can be a little bit slower, but at least it less boilerplate. Also for training flag it may be conveniently to use tflearn train flags\n",
    "![](tf11.png)\n",
    "\n",
    "**********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Applying weights regularization</font>\n",
    "![](tf12.png)\n",
    "*************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Load part of graph from previous run</font>\n",
    "![](tf13.png)\n",
    "************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Count trainable params</font>\n",
    "![](tf14.png)\n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Handle TensorArrays correct way inside tf.while_loop</font>\n",
    "\n",
    "Sometimes we want to pass output from one loop step, to next step. For this we can use tf.TensorArray with read and write operations. But in case we read and write to same tensorarray inside loop - we should manually set number of available while loop parallel_iterations=1. This is because in case of parallel loop execution(parallel_iterations > 1) some thread may try to read info from tensorArray, that was not written to it by another one thread. Try to copy/run code snippet below.\n",
    "![](tf15.png)\n",
    "![](tf16.png)\n",
    "![](tf17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Explore checkpoints file</font>\n",
    "\n",
    "This can be done with such helper methods print_tensors_in_checkpoint_file and pywrap_tensorflow\n",
    "![](tf18.png)\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#053a91'>Restore part of the tensor from saving</font>\n",
    "![](tf19.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
